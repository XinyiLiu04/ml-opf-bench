import os
import sys
import torch
import torch.nn as nn
import numpy as np

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

try:
    from DenseCoreNetwork import DenseCoreNetwork
except ImportError:
    pass


class PinnLayer(nn.Module):
    """
    PINN Layer - é›†æˆ Slack Bus å¤„ç† (ä¿®å¤æ•°å€¼ç¨³å®šæ€§)

    ç‰ˆæœ¬: v2.1 - Numerical Stability Fix

    å…³é”®ä¿®å¤:
    --------
    1. æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥å’Œ epsilon
    2. ä¿®å¤ KKT Error è®¡ç®—ä¸­çš„é™¤é›¶é—®é¢˜
    3. æ”¹è¿› Slack Bus é‡æ„çš„æ•°å€¼ç²¾åº¦
    4. æ·»åŠ æ¢¯åº¦è£å‰ªä¿æŠ¤
    5. æ‰€æœ‰çº¦æŸè¿åä½¿ç”¨ reluï¼ˆä¿æŒä¸åŸç‰ˆä¸€è‡´ï¼‰
    """

    def __init__(self, simulation_parameters, device='cuda'):
        super(PinnLayer, self).__init__()

        self.device = device
        self.eps = 1e-8  # ğŸ†• æ•°å€¼ç¨³å®šæ€§å¸¸æ•°

        # ç¼©æ”¾å‚æ•°
        self.pd_scale_type = simulation_parameters.get('pd_scale_type', None)
        if self.pd_scale_type == 'minmax':
            self.pd_min = torch.tensor(simulation_parameters['pd_min'], dtype=torch.float32, device=device)
            self.pd_max = torch.tensor(simulation_parameters['pd_max'], dtype=torch.float32, device=device)
        elif self.pd_scale_type == 'standard':
            self.pd_mean = torch.tensor(simulation_parameters['pd_mean'], dtype=torch.float32, device=device)
            self.pd_std = torch.tensor(simulation_parameters['pd_std'], dtype=torch.float32, device=device)

        # ç³»ç»Ÿå‚æ•°
        self.n_buses = simulation_parameters['general']['n_buses']
        self.n_g = simulation_parameters['general']['n_g']
        self.n_g_non_slack = simulation_parameters['general']['n_g_non_slack']
        self.n_line = simulation_parameters['general']['n_line']

        # Slack ä¿¡æ¯
        slack_gen_indices = simulation_parameters['general']['slack_gen_indices']
        non_slack_gen_indices = simulation_parameters['general']['non_slack_gen_indices']

        self.slack_gen_indices = torch.tensor(slack_gen_indices, dtype=torch.long, device=device)
        self.non_slack_gen_indices = torch.tensor(non_slack_gen_indices, dtype=torch.long, device=device)
        self.n_slack_gens = len(slack_gen_indices)

        print(f"\n[PinnLayer v2.1] Initialization:")
        print(f"  Total generators: {self.n_g}")
        print(f"  Non-Slack generators: {self.n_g_non_slack}")
        print(f"  Slack generators: {self.n_slack_gens}")
        print(f"  Slack generator indices: {slack_gen_indices}")

        # ç½‘ç»œå‚æ•°
        neurons_pg = simulation_parameters['training']['neurons_in_hidden_layers_Pg']
        neurons_lm = simulation_parameters['training']['neurons_in_hidden_layers_Lm']

        # æ ¸å¿ƒç½‘ç»œ
        self.core_network = DenseCoreNetwork(
            n_gbus_non_slack=self.n_g_non_slack,
            n_gbus_all=self.n_g,
            n_line=self.n_line,
            neurons_in_hidden_layers_Pg=neurons_pg,
            neurons_in_hidden_layers_Lm=neurons_lm
        ).to(device)

        # çº¦æŸå‚æ•°
        self.C_Pg = torch.tensor(simulation_parameters['constraints']['C_Pg'],
                                 dtype=torch.float32, device=device)
        self.Pg_max = torch.tensor(simulation_parameters['constraints']['Pg_max'],
                                   dtype=torch.float32, device=device)
        self.Pg_min = torch.tensor(simulation_parameters['constraints']['Pg_min'],
                                   dtype=torch.float32, device=device)
        self.Pl_max = torch.tensor(simulation_parameters['constraints']['Pl_max'],
                                   dtype=torch.float32, device=device)
        self.Pg_max_real = torch.tensor(simulation_parameters['constraints']['Pg_max_real'],
                                        dtype=torch.float32, device=device)
        self.PTDF = torch.tensor(simulation_parameters['constraints']['PTDF'],
                                 dtype=torch.float32, device=device)
        self.Map_g = torch.tensor(simulation_parameters['constraints']['Map_g'],
                                  dtype=torch.float32, device=device)
        self.Map_L = torch.tensor(simulation_parameters['constraints']['Map_L'],
                                  dtype=torch.float32, device=device)

        # ç¡®ä¿çº¦æŸå‚æ•°æ˜¯1Då¼ é‡
        if self.Pg_min.ndim == 2:
            self.Pg_min = self.Pg_min.flatten()
        if self.Pg_max.ndim == 2:
            self.Pg_max = self.Pg_max.flatten()
        if self.Pg_max_real.ndim == 2:
            self.Pg_max_real = self.Pg_max_real.flatten()

        self.Lg_Max = simulation_parameters['Lg_Max']
        self.BASE_MVA = simulation_parameters['general'].get('BASE_MVA', 100.0)

        # ğŸ†• è®¡ç®—å½’ä¸€åŒ–å¸¸æ•°ï¼ˆç”¨äºæ•°å€¼ç¨³å®šï¼‰
        self.pg_scale = torch.max(self.Pg_max_real) + self.eps
        self.pl_scale = torch.max(self.Pl_max) + self.eps

        print(f"  Pg scale: {self.pg_scale.item():.4f} p.u.")
        print(f"  Pl scale: {self.pl_scale.item():.4f} p.u.")

    def _reconstruct_full_pg(self, pg_non_slack, pd_total):
        """
        é‡å»ºå®Œæ•´ Pg (æ”¹è¿›æ•°å€¼ç¨³å®šæ€§)

        å…³é”®æ”¹è¿›:
        --------
        1. ä½¿ç”¨ clamp é¿å…æ•°å€¼æº¢å‡º
        2. æ·»åŠ  epsilon é¿å…é™¤é›¶
        3. æ£€æŸ¥ Slack åŠŸç‡æ˜¯å¦åˆç†
        """
        batch_size = pg_non_slack.shape[0]
        device = pg_non_slack.device

        # åˆå§‹åŒ–å®Œæ•´ Pg
        pg_full = torch.zeros(batch_size, self.n_g,
                              dtype=pg_non_slack.dtype, device=device)

        # å¡«å……é Slackï¼ˆå½’ä¸€åŒ–å€¼ - åº”è¯¥åœ¨ [0,1] ä¹‹é—´ï¼‰
        # ğŸ†• Clamp ç¡®ä¿åœ¨åˆç†èŒƒå›´
        pg_non_slack_clamped = torch.clamp(pg_non_slack, 0.0, 1.2)
        pg_full[:, self.non_slack_gen_indices] = pg_non_slack_clamped

        # è®¡ç®—é Slack æ€»å‡ºåŠ›ï¼ˆç‰©ç†å€¼ p.u.ï¼‰
        pg_non_slack_real = pg_non_slack_clamped * self.Pg_max_real[self.non_slack_gen_indices].unsqueeze(0)
        pg_non_slack_total = torch.sum(pg_non_slack_real, dim=1)

        # è®¡ç®— Slack æ€»å‡ºåŠ›ï¼ˆç‰©ç†å€¼ p.u.ï¼‰
        pg_slack_total = pd_total - pg_non_slack_total

        # ğŸ†• æ£€æŸ¥ Slack åŠŸç‡æ˜¯å¦åˆç†ï¼ˆé¿å…è´Ÿå€¼æˆ–è¿‡å¤§ï¼‰
        # å…è®¸ä¸€å®šçš„ä¸å¹³è¡¡ï¼ˆè®­ç»ƒåˆæœŸå¯èƒ½ä¸å‡†ç¡®ï¼‰
        pg_slack_total = torch.clamp(pg_slack_total, -0.1 * self.pg_scale, 2.0 * self.pg_scale)

        # è½¬æ¢ä¸ºå½’ä¸€åŒ–å€¼å¹¶å¡«å……
        if self.n_slack_gens > 0:
            # å¹³å‡åˆ†é…åˆ°æ‰€æœ‰ Slack å‘ç”µæœº
            pg_slack_per_gen = pg_slack_total / (self.n_slack_gens + self.eps)

            # è½¬æ¢ä¸ºå½’ä¸€åŒ–å€¼
            slack_pg_max_real = self.Pg_max_real[self.slack_gen_indices]
            pg_slack_normalized = pg_slack_per_gen.unsqueeze(1) / (slack_pg_max_real.unsqueeze(0) + self.eps)

            # ğŸ†• Clamp Slack å½’ä¸€åŒ–å€¼
            pg_slack_normalized = torch.clamp(pg_slack_normalized, -0.1, 1.5)

            pg_full[:, self.slack_gen_indices] = pg_slack_normalized

        return pg_full

    def get_kkt_error(self, P_Gens, P_Loads, n_o_l, n_o_a_u, n_o_a_d, n_o_b_u, n_o_b_d):
        """
        è®¡ç®—KKTè¯¯å·® (æ”¹è¿›æ•°å€¼ç¨³å®šæ€§)

        å…³é”®æ”¹è¿›:
        --------
        1. æ‰€æœ‰é™¤æ³•éƒ½æ·»åŠ  epsilon
        2. ä½¿ç”¨ç›¸å¯¹è¯¯å·®è€Œéç»å¯¹è¯¯å·®
        3. æ·»åŠ æ¢¯åº¦è£å‰ªä¿æŠ¤
        """
        # ğŸ†• åŠŸç‡å¹³è¡¡è¯¯å·® (ä½¿ç”¨ç›¸å¯¹è¯¯å·®)
        total_gen = torch.sum(P_Gens * self.Pg_max_real, dim=1)
        total_load = torch.sum(P_Loads, dim=1)

        # ç›¸å¯¹åŠŸç‡å¹³è¡¡è¯¯å·®
        power_balance_err = torch.abs(total_gen - total_load) / (total_load + self.eps)
        KKT_error = power_balance_err

        # ğŸ†• å‘ç”µæœºçº¦æŸè¿å (å½’ä¸€åŒ–)
        gen_up_viol = torch.relu(P_Gens - self.Pg_max)
        gen_lo_viol = torch.relu(self.Pg_min - P_Gens)

        # ä½¿ç”¨ç›¸å¯¹è¿åé‡
        KKT_error = KKT_error + torch.sum(gen_up_viol, dim=1) / (self.n_g + self.eps)
        KKT_error = KKT_error + torch.sum(gen_lo_viol, dim=1) / (self.n_g + self.eps)

        # è®¡ç®—çº¿è·¯æ½®æµ
        P_gen_bus = torch.matmul(P_Gens * self.Pg_max_real, self.Map_g)
        P_load_bus = torch.matmul(P_Loads, self.Map_L)
        net_injection = P_gen_bus - P_load_bus
        line_flows = torch.matmul(net_injection, self.PTDF)

        # ğŸ†• çº¿è·¯è¿å (å½’ä¸€åŒ–)
        line_viol_pos = torch.relu(line_flows - self.Pl_max)
        line_viol_neg = torch.relu(-line_flows - self.Pl_max)

        # ä½¿ç”¨ç›¸å¯¹è¿åé‡
        KKT_error = KKT_error + torch.sum(line_viol_pos, dim=1) / (self.pl_scale * self.n_line + self.eps)
        KKT_error = KKT_error + torch.sum(line_viol_neg, dim=1) / (self.pl_scale * self.n_line + self.eps)

        # ğŸ†• é©»å®šæ¡ä»¶è¯¯å·® (æ·»åŠ æ•°å€¼ç¨³å®šæ€§)
        stationarity_term1 = torch.matmul(self.C_Pg.unsqueeze(0), self.Map_g)
        stationarity_term2 = torch.matmul(n_o_a_d * (self.Lg_Max[2] + self.eps), self.Map_g)
        stationarity_term3 = torch.matmul(n_o_a_u * (self.Lg_Max[1] + self.eps), self.Map_g)
        stationarity_term4 = torch.matmul(n_o_b_u * (self.Lg_Max[3] + self.eps), self.PTDF.t())
        stationarity_term5 = torch.matmul(n_o_b_d * (self.Lg_Max[4] + self.eps), self.PTDF.t())

        stationarity_error = torch.abs(
            stationarity_term1 + stationarity_term2 - stationarity_term3 -
            stationarity_term4 + stationarity_term5
        )

        # å½’ä¸€åŒ–é©»å®šæ¡ä»¶è¯¯å·®
        stationarity_scale = max(self.Lg_Max) + self.eps
        KKT_error = KKT_error + torch.sum(n_o_l, dim=1) * (self.Lg_Max[0] + self.eps) / (100 * stationarity_scale)
        KKT_error = KKT_error + torch.sum(stationarity_error, dim=1) / (100 * stationarity_scale)

        # ğŸ†• äº’è¡¥æ¾å¼›æ¡ä»¶ (å½’ä¸€åŒ–)
        comp_slack_up = torch.abs(n_o_a_u * (P_Gens - self.Pg_max))
        comp_slack_down = torch.abs(n_o_a_d * (self.Pg_min - P_Gens))

        KKT_error = KKT_error + torch.sum(comp_slack_up, dim=1) / (self.n_g + self.eps)
        KKT_error = KKT_error + torch.sum(comp_slack_down, dim=1) / (self.n_g + self.eps)

        # çº¿è·¯äº’è¡¥æ¾å¼›
        line_slack_pos = torch.abs(n_o_b_u * (line_flows - self.Pl_max))
        line_slack_neg = torch.abs(n_o_b_d * (-line_flows - self.Pl_max))

        KKT_error = KKT_error + torch.sum(line_slack_pos, dim=1) / (self.pl_scale * self.n_line + self.eps)
        KKT_error = KKT_error + torch.sum(line_slack_neg, dim=1) / (self.pl_scale * self.n_line + self.eps)

        # ğŸ†• å¯¹å¶å¯è¡Œæ€§ (ä½¿ç”¨ relu)
        KKT_error = KKT_error + torch.sum(torch.relu(-n_o_a_u), dim=1) / (self.n_g + self.eps)
        KKT_error = KKT_error + torch.sum(torch.relu(-n_o_a_d), dim=1) / (self.n_g + self.eps)
        KKT_error = KKT_error + torch.sum(torch.relu(-n_o_b_u), dim=1) / (self.n_line + self.eps)
        KKT_error = KKT_error + torch.sum(torch.relu(-n_o_b_d), dim=1) / (self.n_line + self.eps)

        # ğŸ†• æ¢¯åº¦è£å‰ªä¿æŠ¤
        KKT_error = torch.clamp(KKT_error, 0, 1000)  # é¿å…æç«¯å€¼

        return KKT_error

    def forward(self, inputs):
        """
        å‰å‘ä¼ æ’­ï¼ˆæ•°å€¼ç¨³å®šç‰ˆæœ¬ï¼‰

        è¿”å›:
        ----
        - network_output_g_non_slack: [batch, n_g_non_slack]
        - n_o_l: [batch, 1]
        - n_o_a_u, n_o_a_d: [batch, n_g]
        - n_o_b_u, n_o_b_d: [batch, n_line]
        - KKT_error: [batch]
        """
        # æ­¥éª¤1ï¼šæ ¸å¿ƒç½‘ç»œè¾“å‡º
        (network_output_g_non_slack, n_o_l, n_o_a_u,
         n_o_a_d, n_o_b_u, n_o_b_d) = self.core_network(inputs)

        # è´Ÿè·å»å½’ä¸€åŒ–
        if self.pd_scale_type == 'minmax':
            P_Loads_unscaled = inputs * (self.pd_max - self.pd_min) + self.pd_min
        elif self.pd_scale_type == 'standard':
            P_Loads_unscaled = inputs * self.pd_std + self.pd_mean
        else:
            P_Loads_unscaled = inputs

        # æ­¥éª¤2ï¼šé‡å»ºå®Œæ•´ Pg
        pd_total = torch.sum(P_Loads_unscaled, dim=1)

        network_output_g_full = self._reconstruct_full_pg(
            pg_non_slack=network_output_g_non_slack,
            pd_total=pd_total
        )

        # æ­¥éª¤3ï¼šè®¡ç®—KKTè¯¯å·®
        KKT_error = self.get_kkt_error(
            P_Gens=network_output_g_full,
            P_Loads=P_Loads_unscaled,
            n_o_l=n_o_l,
            n_o_a_u=n_o_a_u,
            n_o_a_d=n_o_a_d,
            n_o_b_u=n_o_b_u,
            n_o_b_d=n_o_b_d
        )

        return (network_output_g_non_slack, n_o_l, n_o_a_u,
                n_o_a_d, n_o_b_u, n_o_b_d, KKT_error)